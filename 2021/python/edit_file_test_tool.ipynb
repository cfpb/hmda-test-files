{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roellr/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pandas/compat/__init__.py:84: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "/Users/roellr/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pandas/compat/__init__.py:84: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import json\n",
    "import os\n",
    "from os.path import join, isfile\n",
    "from os import listdir, makedirs, path\n",
    "\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "#Edit report configurations are located in configurations/edit_report_config.yaml\n",
    "import lar_generator\n",
    "from rules_engine import rules_engine\n",
    "\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows = 999\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load configurations\n",
    "lar_config_file = 'configurations/clean_file_config.yaml'\n",
    "bank_config = \"configurations/bank1_config.yaml\"\n",
    "geo_config_file='configurations/geographic_data.yaml'\n",
    "filepaths_file = 'configurations/test_filepaths.yaml'\n",
    "lar_schema_file=\"../schemas/lar_schema.json\"\n",
    "ts_schema_file=\"../schemas/ts_schema.json\"\n",
    "lar_2018_haeder = []\n",
    "\n",
    "with open(lar_schema_file, \"r\") as in_schema:\n",
    "    lar_schema = in_schema.readlines()\n",
    "lar_schema = [line.strip(\"\\n\") for line in lar_schema]\n",
    "lar_string = \"\".join([line for line in lar_schema])\n",
    "lar_json = json.loads(lar_string)\n",
    "lar_2018_header = []\n",
    "for row in lar_json:\n",
    "    lar_2018_header.append(row[\"field\"])\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open configuration files and load data\n",
    "with open(lar_config_file, 'r') as f:\n",
    "\tlar_file_config_data = yaml.safe_load(f)\n",
    "\n",
    "with open(filepaths_file, 'r') as f:\n",
    "\tfilepaths = yaml.safe_load(f)\n",
    "\n",
    "with open(geo_config_file, 'r') as f:\n",
    "\tgeo_config = yaml.safe_load(f)\n",
    "\n",
    "with open(bank_config, 'r') as f:\n",
    "\tbank_config_data = yaml.safe_load(f)\n",
    "\n",
    "with open(geo_config[\"zip_code_file\"], 'r') as f:\n",
    "\tzip_codes = json.load(f)\n",
    "    \n",
    "zip_codes.append(\"Exempt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start initialization of LAR generator\n",
      "LAR generator initialization complete\n",
      "initializing rules engine\n",
      "loading config files for rules engine\n",
      "opening json schema files\n",
      "schema loaded\n",
      "rules engine finished initializing\n"
     ]
    }
   ],
   "source": [
    "geographic_data = pd.read_csv(geo_config['geographic_data_file'], delimiter=',', header=0,\n",
    "\tnames=geo_config['file_columns'], dtype=object) #instantiate Census file data as dataframe\n",
    "\n",
    "#create 11 digit Census Tract codes from 5 digit county and 6 digit tract\n",
    "geographic_data['county_fips'] = geographic_data.apply(lambda x: str(x.state_code) + str(x.county), axis=1)\n",
    "geographic_data[\"tract_fips\"] = geographic_data.apply(lambda x: str(x.county_fips) + str(x.tracts), axis=1)\n",
    "\n",
    "with open(geo_config[\"zip_code_file\"], 'r') as f: \n",
    "\tzip_codes = json.load(f)\n",
    "zip_codes.append(\"Exempt\")#add exempt as a valid ZIP Code\n",
    "\n",
    "#instantiate lar generator to create random LAR and fixed TS data\n",
    "lar_gen = lar_generator.lar_gen(lar_schema_file=lar_schema_file, ts_schema_file=ts_schema_file)\n",
    "\n",
    "#instantiate rules engine to check conformity of synthetic data to FIG schema\n",
    "#rules engine creates edit reports to see which edits were failed by which rows in which file\n",
    "rules_engine = rules_engine(config_data=lar_file_config_data, state_codes=geo_config[\"state_codes\"], state_codes_rev=geo_config[\"state_codes_rev\"],\n",
    "\tgeographic_data=geographic_data, full_lar_file_check=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edit report save path ../edit_reports/\n",
      "clean file dir ['../edits_files/Bank1/clean_files/']\n",
      "valdity test file dir ../edits_files/Bank1/test_files/validity/\n",
      "syntax test file dir ../edits_files/Bank1/test_files/syntax/\n",
      "quality test file dir ../edits_files/Bank1/test_files/quality/\n",
      "s/v clean quality test file dir ../edits_files/Bank1/test_files/quality_pass_s_v/\n"
     ]
    }
   ],
   "source": [
    "#set location for edit report CSV writing\n",
    "edit_report_path = filepaths[\"edit_report_output_filepath\"] \n",
    "\n",
    "#get paths to check for clean files (by bank name) \n",
    "#store as list to match edit files format\n",
    "clean_filepath = [filepaths[\"clean_filepath\"].format(bank_name=bank_config_data[\"name\"][\"value\"])]\n",
    "\n",
    "#get directories to check for files\n",
    "bank_test_v_dir = filepaths[\"validity_filepath\"].format(bank_name=bank_config_data[\"name\"][\"value\"])\n",
    "bank_test_s_dir = filepaths[\"syntax_filepath\"].format(bank_name=bank_config_data[\"name\"][\"value\"])\n",
    "bank_test_q_dir = filepaths[\"quality_filepath\"].format(bank_name=bank_config_data[\"name\"][\"value\"])\n",
    "bank_test_q_pass_dir = filepaths[\"quality_pass_s_v_filepath\"].format(bank_name=bank_config_data[\"name\"][\"value\"])\n",
    "\n",
    "edit_filepaths = [bank_test_v_dir, bank_test_s_dir, bank_test_q_dir]\n",
    "print(\"edit report save path\", edit_report_path)\n",
    "print(\"clean file dir\", clean_filepath)\n",
    "print(\"valdity test file dir\", bank_test_v_dir)\n",
    "print(\"syntax test file dir\", bank_test_s_dir)\n",
    "print(\"quality test file dir\", bank_test_q_dir)\n",
    "print(\"s/v clean quality test file dir\", bank_test_q_pass_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_names(filepaths):\n",
    "    \"\"\"\n",
    "    filepaths: list of paths to check for files\n",
    "    file_names: list of files in the path(s)\n",
    "    \"\"\"\n",
    "    file_names = []\n",
    "    for path in filepaths:\n",
    "    #concat edit file path to edit file name to make looping easier in edit check\n",
    "        new_file_names = [path+f for f in listdir(path) if isfile(join(path, f))]\n",
    "        file_names = file_names + new_file_names\n",
    "    \n",
    "    try:\n",
    "        file_names = [f for f in file_names if '.DS_Store' not in f]\n",
    "    except:\n",
    "        print(\"no DS Store to remove\")\n",
    "    file_names.sort()\n",
    "    print(len(file_names), \"files found in {filepaths}\".format(filepaths=filepaths))\n",
    "    return file_names\n",
    "\n",
    "def generate_edit_report(file_list, save_name, edits_list=[\"s\",\"v\",\"q\",\"m\"], save_path=edit_report_path, \n",
    "                         save_report=True):\n",
    "    \"\"\"\n",
    "    file_list: list of files to check against rules engine\n",
    "    edits_list: list of edit types to check options are s, v, q, m\n",
    "    \"\"\"\n",
    "    #set up data frame seed for edit report to use as a base for concatenation\n",
    "    report_df = pd.DataFrame([], columns=['file_name', 'edit_name', 'row_type', 'field', 'fail_count', 'failed_rows', \"file_edit_name\"], index=[0])\n",
    "    for file in file_list: #iterate over clean test files and create report results for each\n",
    "        rules_engine.reset_results() #clear previous edit report results\n",
    "        #print(file) #display current working file\n",
    "        ts_df, lar_df = rules_engine.split_ts_row(file) #split TS row from LAR data for dataframe usage\n",
    "        #load current file data to rules engine to create edit report\n",
    "        rules_engine.load_ts_data(ts_df)\n",
    "        rules_engine.load_lar_data(lar_df)\n",
    "        #generate edit report\n",
    "        new_results_df = rules_engine.create_edit_report(edits_list)\n",
    "        new_results_df[\"file_name\"] = file #label file_name in report\n",
    "        new_results_df[\"file_edit_name\"] = new_results_df.file_name.apply(lambda x: x.split(\"/\")[-1].split(\"_\")[-1].replace(\".txt\",\"\"))\n",
    "        report_df = pd.concat([report_df, new_results_df])\n",
    "        report_df.reset_index(drop=True, inplace=True)\n",
    "        report_df.drop(0, inplace=True)\n",
    "    if save_report:\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        report_df.to_csv(save_path + save_name, sep=\"|\", index=False)\n",
    "    return report_df\n",
    "\n",
    "### check if all files were created: use rules engine list\n",
    "#get list of ones missing\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 files found in ['../edits_files/Bank1/clean_files/']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'set' and 'set'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e4a1a7c966e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclean_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_file_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfilepaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_file_report_output_filename'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbank_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbank_config_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclean_report_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_edit_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilepaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_file_report_output_filename'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbank_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbank_config_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-2cc4feabf829>\u001b[0m in \u001b[0;36mgenerate_edit_report\u001b[0;34m(file_list, save_name, edits_list, save_path, save_report)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mrules_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_lar_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlar_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m#generate edit report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mnew_results_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrules_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_edit_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medits_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mnew_results_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"file_name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;31m#label file_name in report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mnew_results_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"file_edit_name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_results_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/OneDrive - CFPB/hmda_repos/hmda-test-files/2021/python/rules_engine.py\u001b[0m in \u001b[0;36mcreate_edit_report\u001b[0;34m(self, rules_list)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mrule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mrule\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrules_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrule\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                                 \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mres_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/OneDrive - CFPB/hmda_repos/hmda-test-files/2021/python/rules_engine.py\u001b[0m in \u001b[0;36mm647\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4074\u001b[0m \t\t\"\"\"\n\u001b[1;32m   4075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4076\u001b[0;31m                 \u001b[0mfield\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"exempt_string_fields\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"exempt_integer_fields\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Federal Agency\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4077\u001b[0m                 \u001b[0medit_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"q647\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4078\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mts_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'federal_agency'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'7'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'set' and 'set'"
     ]
    }
   ],
   "source": [
    "clean_files = get_file_names(clean_filepath)\n",
    "filepaths['clean_file_report_output_filename'].format(bank_name=bank_config_data[\"name\"][\"value\"])\n",
    "clean_report_df = generate_edit_report(clean_files, save_name=filepaths['clean_file_report_output_filename'].format(bank_name=bank_config_data[\"name\"][\"value\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_report_df[clean_report_df.fail_count>0].edit_name.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open clean file to see issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_filepath: \"../edits_files/{bank_name}/clean_files/\"\n",
    "clean_filename = \"Bank1_clean_100_rows.txt\"\n",
    "clean_file = filepaths[\"clean_filepath\"].format(bank_name=bank_config_data[\"name\"][\"value\"]) \\\n",
    "                                                + clean_filename\n",
    "clean_file_df = pd.read_csv(clean_file, sep=\"|\", dtype=object, keep_default_na=False, \n",
    "                            header=None, skiprows=1, names=lar_2018_header)\n",
    "clean_file_df[[\"const_method\", \"manufactured_type\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "edit_files = get_file_names(edit_filepaths)\n",
    "edit_report_df = generate_edit_report(edit_files, save_name=\n",
    "                                      filepaths['edit_report_output_filename'].format(bank_name=\n",
    "                                                                                      bank_config_data[\"name\"][\"value\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#edit_report_df[((edit_report_df.file_edit_name.isin([\"q648\", \"q651\"]))&(edit_report_df.fail_count>0))&\n",
    " #             (edit_report_df.edit_name.apply(lambda x: x[:1] in (\"s\", \"v\")))]\n",
    "\n",
    "edit_report_df[(edit_report_df.file_name==edit_report_df.file_edit_name)]\n",
    "\n",
    "edit_report_df.file_edit_name.unique()\n",
    "edit_report_df[[\"edit_name\", \"fail_count\", \"field\", \"file_edit_name\", \"file_name\", \"row_type\"]][(edit_report_df.fail_count>=500)&\n",
    "                                                     (edit_report_df.file_name.apply(lambda x: \"q\" not in x))&\n",
    "                                                     (edit_report_df.edit_name.apply(lambda x: x[:1] in (\"s\", \"v\")))&\n",
    "                                                    (edit_report_df.apply(lambda x: ))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Stop here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"../edits_files/Abhinayaa Bank/test_files/validity/Abhinayaa Bank_500_v673_1.txt\"\n",
    "ts_df, lar_df = rules_engine.split_ts_row(data_file)\n",
    "lar_df.head()\n",
    "type(lar_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Edit Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fail_ulis(report_df, edit_name_list, file_name):\n",
    "    \"\"\"\n",
    "    returns a list of ULIs failing the specified edits\n",
    "    edit_name_list: list of edits IE q648\n",
    "    file_name: name of file in edit report IE Chynna Bank_clean_500_rows.txt\n",
    "    \"\"\"\n",
    "    fail_rows = report_df.failed_rows[(report_df.file_name==file_name)&\n",
    "               (report_df.edit_name.isin(edit_name_list))].iloc[0]\n",
    "    fail_rows = fail_rows.strip(\"']['\").split(\", \")\n",
    "    fail_rows = [row.replace(\"'\",\"\") for row in fail_rows]\n",
    "    return fail_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_report_df = pd.read_csv(edit_report_path + \\\n",
    "                             filepaths['clean_file_report_output_filename'].format(bank_name=bank_config_data[\"name\"][\"value\"]),\n",
    "                            sep=\"|\")\n",
    "\n",
    "clean_report_df[(clean_report_df.file_name==\"Chynna Bank_clean_500_rows.txt\")&\n",
    "               (clean_report_df.edit_name.isin([\"q648\"]))]\n",
    "\n",
    "q648_fails = get_fail_ulis(clean_report_df, [\"q648\"], \"Chynna Bank_clean_500_rows.txt\")\n",
    "clean_report_df[(clean_report_df.file_name==\"Chynna Bank_clean_500_rows.txt\")&\n",
    "               (clean_report_df.failed_rows.apply(lambda x: len(x) !=2))]\n",
    "\n",
    "clean_report_df[clean_report_df.edit_name.apply(lambda x: x[:1]==\"v\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bank_clean_dir)\n",
    "col_list = [\"action_taken\", \"uli\", \"lei\"]\n",
    "test_file_df = pd.read_csv(bank_clean_dir+\"Chynna Bank_clean_500_rows.txt\", sep=\"|\", header=None, names=lar_2018_header,\n",
    "                           skiprows=[0], dtype=object)\n",
    "test_file_df[col_list][test_file_df.uli.isin(q648_fails)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1) If Action Taken equals 1, 2, 3, 4, 5, 7, or 8, the first\n",
    "20 characters of the ULI should match the reported\n",
    "LEI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load edit file report\n",
    "test_report_df = pd.read_csv(edit_report_path + \\\n",
    "                             filepaths['edit_report_output_filename'].format(bank_name=bank_config_data[\"name\"][\"value\"]),\n",
    "                            sep=\"|\")\n",
    "\n",
    "test_report_df[test_report_df.file_name==\"../edits_files/Chynna Bank/test_files/quality/Chynna Bank_500_q648.txt\"]\n",
    "test_report_df.iloc[:,:-2][test_report_df.edit_name==\"v610_2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_df = pd.read_csv(\"../edits_files/Chynna Bank/test_files/quality/Chynna Bank_500_q651.txt\", sep=\"|\", header=None, names=lar_2018_header,\n",
    "                           skiprows=[0], dtype=object, keep_default_na=False)\n",
    "test_file_df[[\"action_taken\", \"app_date\"]]#[(test_file_df.action_taken.isin([\"6\"]))]#&(~test_file_df.app_date.isin([\"NA\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_file_df[((test_file_df.app_date==\"NA\")&(test_file_df.action_taken!=\"6\"))|\n",
    "\t\t\t\t((test_file_df.action_taken==\"6\")&(test_file_df.app_date!=\"NA\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
